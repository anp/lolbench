#[macro_use]
extern crate failure;
#[macro_use]
extern crate structopt;

extern crate chrono;
extern crate clap;
extern crate log;
extern crate lolbench;
extern crate simple_logger;

use lolbench::*;

use std::path::PathBuf;

use chrono::{NaiveDate, Utc};
use structopt::StructOpt;

fn main() -> Result<()> {
    simple_logger::init_with_level(log::Level::Debug).unwrap();
    Cli::from_args().exec()
}

#[derive(Debug, StructOpt)]
struct Generate {
    /// Name of the benchmark crate to add.
    name: String,
}

impl Generate {
    fn run(self) -> Result<()> {
        generate_new_benchmark_crate(&self.name)
    }
}

#[derive(Debug, StructOpt)]
struct Measure {
    // TODO(anp): structopt mangles this help message horribly
    /// Selects specific CPUs on which *only* benchmarks will run. Currently only supported when run
    /// as root on Linux. Accepts a pattern of CPU IDs and ID ranges delimited by commas
    /// (e.g. 0,1,2 or 0-2,4). Defaults to performing no CPU isolation.
    #[structopt(short = "c", long = "cpus")]
    cpu_pattern: Option<String>,

    /// If a CPU pattern is set, also ask the kernel to try to relocate kernel tasks off of
    /// benchmark CPUs.
    #[structopt(short = "k", long = "move-kthreads")]
    move_kernel_threads: bool,

    /// Limit the benchmarks run to those assigned to the given runner.
    #[structopt(long = "runner")]
    runner: Option<String>,

    /// Run benchmarks with a single toolchain.
    #[structopt(long = "single-toolchain")]
    single_toolchain: Option<String>,

    /// Run benchmarks with nightlies starting from a specific.
    #[structopt(long = "nightlies-since")]
    nightlies_since: Option<NaiveDate>,

    /// Path to data directory. Will be created if empty.
    #[structopt(long = "data-dir", parse(from_os_str))]
    data_dir: PathBuf,

    /// Path to site directory. Will be created if empty.
    #[structopt(long = "site-dir", parse(from_os_str))]
    site_dir: PathBuf,

    /// If passed, we'll attempt to upload the website when committing to the data directory.
    #[structopt(long = "publish")]
    publish: bool,
}

impl Measure {
    fn run(self) -> Result<()> {
        let toolchains = match self {
            Self {
                single_toolchain: Some(toolchain),
                nightlies_since: None,
                ..
            } => ToolchainSpec::Single(toolchain.clone()),

            Self {
                single_toolchain: None,
                nightlies_since: Some(start),
                ..
            } => ToolchainSpec::Range(start.clone(), Utc::today().naive_utc()),

            _ => bail!("unsupported toolchain configuration"),
        };

        let kthread_on = self.move_kernel_threads;

        let shield_spec = self.cpu_pattern.as_ref().map(move |cpus| ShieldSpec {
            cpu_mask: cpus.to_string(),
            kthread_on,
        });

        let opts = BenchOpts {
            toolchains,
            runner: self.runner.clone(),
            shield_spec,
        };

        measure(opts, &self.data_dir, &self.site_dir, self.publish)
    }
}

/// Run benchmarks to assess the performance of code generated by Rust toolchains.
#[derive(StructOpt, Debug)]
pub struct Cli {
    #[structopt(subcommand)]
    cmd: SubCommand,
}

#[derive(Debug, StructOpt)]
enum SubCommand {
    #[structopt(name = "generate-crate")]
    Generate {
        #[structopt(flatten)]
        inner: Generate,
    },
    #[structopt(name = "measure")]
    Measure {
        #[structopt(flatten)]
        inner: Measure,
    },
    #[structopt(name = "rebalance-benchmarks")]
    Rebalance {
        #[structopt(long = "sample-dir", parse(from_os_str))]
        sample_dir: PathBuf,
    },
    #[structopt(name = "build-website")]
    Present {
        #[structopt(long = "data-dir", parse(from_os_str))]
        data_dir: PathBuf,
        #[structopt(long = "output-dir", parse(from_os_str))]
        output_dir: PathBuf,
        #[structopt(long = "publish")]
        publish: bool,
    },
}

impl Cli {
    pub fn exec(self) -> Result<()> {
        match self.cmd {
            SubCommand::Measure { inner } => inner.run(),
            SubCommand::Generate { inner } => inner.run(),
            SubCommand::Rebalance { sample_dir } => rebalance(sample_dir),
            SubCommand::Present {
                data_dir,
                output_dir,
                publish,
            } => build_website(data_dir, output_dir, publish),
        }
    }
}
